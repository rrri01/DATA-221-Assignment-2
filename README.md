# DATA-221-Assignment-2

Question 1:
This program reads the text file, only keeps track of words containing 2 or more alphabetic characters, removes punctuation, splits it into words, converts the words to lowercase. Then it figures out which words appear the most frequently, and displays the top 10 most frequent words and how many times it appears.

Question 2:
This program creates bigrams from all of the words in the file that have 2 or more characters.
Then it counts how frequent each bigram is and displays the top 5 most frequen bigrams, in order of most to least.

Question 3:
This program "normalizes" each line in the file, and figures out how many near-duplicates there are. The program will print the first 2 sets of near-duplicates, and their line numbers.

Question 4:
This program reads the student.csv and loads the dataset into a dataframe. Then it filters the data and only uses a few columns.
Then it saves these filtered data columns to high_engagement.csv
Then the program will print the number of students, and the average grade.

Question 5:
This program uses the student.csv file, and creates the new column, grade_band. It assigns a rank of "Low" or "Medium" or "High" to each student based on their grade.
Then the program creates a table displaying the number of students, average absences per student, and percentage of students with internet access, and saves it to student_bands.csv

Question 6:
This program uses the crime.csv file, and creates a column, "risk," based on the ViolentCrimesPerPop column. The risk is either set to "HighCrime" or "LowCrime." Then the data is grouped by the risk column. For each group (HighCrime and LowCrime), the program will find the average unemployment rate for each.

Question 7:
This program scrapes the given wikipedia page, and uses "requests" and "BeautifulSoup" to find the "title" and also




